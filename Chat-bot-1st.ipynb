{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48d1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m753.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Collecting tqdm (from openai)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp (from openai)\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ian/.pyenv/versions/3.10.6/envs/FunesBot/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tqdm, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 tqdm-4.65.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm a chatbot that can answer questions about the novel 'War and Peace'. What would you like to know?\n",
      "You: What are the main characters?\n",
      "Chatbot: The main characters in War and Peace are Pierre Bezukhov, Andrei Bolkonsky, Natasha Rostova, Prince Andrei Bolkonsky, Princess Marya Bolkonskaya, Count Nikolai Rostov, Sonya Rostova, Prince Nikolai Bolkonsky, Princess Liza Bolkonskaya, and Count Pierre Bezukhov.\n",
      "You: Tell me more about Pierre \n",
      "Chatbot: Chatbot: Pierre Bezukhov is the illegitimate son of a wealthy count. He is a kindhearted, idealistic man who is searching for the meaning of life. He eventually finds love and happiness with Natasha Rostova. He is a central character in War and Peace and his story is used to illustrate the effects of the Napoleonic era on Russian society.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Define the context for the chatbot\n",
    "context = \"\"\"War and Peace is a novel by the great Russian author Leo Tolstoy, published from 1865 to 1869. \n",
    "It is set in the period of the French invasion of Russia and the impact of the Napoleonic era on Tsarist society through the stories of five Russian aristocratic families. \n",
    "Characters in the book include Pierre Bezukhov, Andrei Bolkonsky, and Natasha Rostova.\"\"\"\n",
    "\n",
    "def get_response(prompt):\n",
    "    prompt_with_context = context + \"\\n\" + prompt\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt_with_context,\n",
    "        temperature=0.5,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def chat():\n",
    "    conversation_history = \"\"\n",
    "    print(\"Hello! I'm a chatbot that can answer questions about the novel 'War and Peace'. What would you like to know?\")\n",
    "    \n",
    "    while True:\n",
    "        # Get the user's query\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() == \"quit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Add the user's query to the conversation history\n",
    "        conversation_history += \"You: \" + user_query + \"\\n\"\n",
    "\n",
    "        # Get a response from the model\n",
    "        response = get_response(conversation_history)\n",
    "\n",
    "        # Add the model's response to the conversation history\n",
    "        conversation_history += response + \"\\n\"\n",
    "\n",
    "        # Print the model's response\n",
    "        print(\"Chatbot: \" + response)\n",
    "\n",
    "# Start the chat\n",
    "chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
